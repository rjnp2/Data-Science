# The Mathematics of Machine Learning

Machine Learning theory is a field that intersects statistical, probabilistic, computer science and algorithmic aspects arising from learning iteratively from data and finding hidden insights which can be used to build intelligent applications.

![105940599-c9f21580-6083-11eb-8754-1322d5eaa4ad](https://user-images.githubusercontent.com/58425689/107522138-7b905b00-6bdb-11eb-9e3b-3dfcad4ca486.png)
![105940669-eee68880-6083-11eb-9f18-caa1d33f07dd](https://user-images.githubusercontent.com/58425689/107522146-7d5a1e80-6bdb-11eb-8a1c-8c3ba64d9091.png)

## 1. Linear Algebra:
  - Linear algebra is a sub-field of mathematics concerned with vectors, matrices, and linear transforms.
  - We represent numerical data as vectors and represent a table of such data as a matrix. The study of vectors and matrices is called linear algebra.
  - It is a key foundation to the field of machine learning, from notations used to describe the operation of algorithms to the implementation of algorithms in code.  
  - Topics such as
       - [**Simple_Algebra**](https://github.com/rjnp2/Data-Science/blob/main/tutorial/3.%20Mathematics/1.%20linear_algebra/1.%20algebra.md), [**Vectors_Spaces**](https://github.com/rjnp2/Data-Science/blob/main/tutorial/3.%20Mathematics/1.%20linear_algebra/2.%20vector.md) and [**Norms**](https://github.com/rjnp2/Data-Science/blob/main/tutorial/3.%20Mathematics/1.%20linear_algebra/3.%20vector_norm.md) 
       - [**Matrices and it's Operations, Matrix Decomposition/Factorization, Singular Value Decomposition (SVD),Orthogonalization & Orthonormalization**](https://github.com/rjnp2/Data-Science/blob/main/tutorial/3.%20Mathematics/1.%20linear_algebra/4.%20Matrices.md)
       - [**Eigenvalues & Eigenvectors, Eigendecomposition of a matrix , Principal Component Analysis (PCA)**](https://github.com/rjnp2/Data-Science/blob/main/tutorial/3.%20Mathematics/1.%20linear_algebra/5.%20Eigenvalues%20%26%20Eigenvectors.md)
  
## 2. Multivariate Calculus: 
  [cheat sheet](https://github.com/rjnp2/Data-Science/tree/main/tutorial/3.%20Mathematics/2.%20Multivariate%20Calculus)
  - Some of the necessary topics include 
      - **Differential and Integral Calculus, Partial Derivatives, Vector-Values Functions, Directional Gradient** 
      
## 3. Probability Theory and Statistics: 
  - Topics such as      
    - [**1. Counting Techniques**](https://github.com/rjnp2/Data-Science/blob/main/tutorial/3.%20Mathematics/3.%20Probabilities%20and%20Statistics/1.%20Counting_Techniques.md)
    - **2. Descriptive Statistics** \
      Statistics is the discipline that concerns the collection, organization, analysis, interpretation, and presentation of data. In applying statistics to a scientific, industrial, or social problem, it is conventional to begin with a statistical population or a statistical model to be studied. In it, **Population and Sample Data, Types of Statistics , Measures of Central Tendency, Measures of Asymmetry, Measures of Variability(Dispersion), Measures of Position, Measurements of Relationships between Variables.** [For more details](https://github.com/rjnp2/Data-Science/blob/main/tutorial/3.%20Mathematics/3.%20Probabilities%20and%20Statistics/2.%20Descriptive_Statistics.md)
    - **3. Probabilities** \
      Probability is the branch of mathematics concerning numerical descriptions of how likely an event is to occur, or how likely it is that a proposition is true. The probability of an event is a number between 0 and 1, where, roughly speaking, 0 indicates impossibility of the event and 1 indicates certainty. In it, **Probability Rules & Axioms, Bayesâ€™ Theorem, Random Variables,Variance and Expectation, Conditional and Joint Distributions, Standard Distributions (Bernoulli, Binomial, Multinomial, Uniform and Gaussian.**[For more details](https://github.com/rjnp2/Data-Science/blob/main/tutorial/3.%20Mathematics/3.%20Probabilities%20and%20Statistics/Probabilities.md)

    - **Statistics - Inferential** \
    - **Moment Generating Functions, Maximum Likelihood Estimation (MLE), Prior and Posterior, Maximum a Posteriori Estimation (MAP).**
        
## 4. Algorithms and Complex Optimizations: 
  - This is important for understanding the computational efficiency and scalability of our Machine Learning Algorithm and for exploiting sparsity in our            datasets.
  - Knowledge of
  
      - **data structures (Binary Trees, Hashing, Heap, Stack etc),Randomized & Sublinear Algorithm, Graphs, Gradient/Stochastic Descents and Primal-Dual methods**

## 5. Others: 
  - This comprises of other Math topics not covered in the four major areas described above. 
  - They include 
  
      - **Real and Complex Analysis (Sets and Sequences, Topology, Metric Spaces, Cauchy Kernel, Fourier Transforms)** 
      
      - **Information Theory (Entropy, Information Gain)** 
      - **Function Spaces and Manifolds.**
